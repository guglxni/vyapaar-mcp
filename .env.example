# ============================================
# Vyapaar MCP — Environment Configuration
# ============================================
# Copy to .env and fill in real values:
#   cp .env.example .env

# --- Razorpay X (Sandbox) ---
VYAPAAR_RAZORPAY_KEY_ID=rzp_test_xxxxxxxxxxxx
VYAPAAR_RAZORPAY_KEY_SECRET=xxxxxxxxxxxxxxxxxxxxxxxx
VYAPAAR_RAZORPAY_WEBHOOK_SECRET=
# Account number from RazorpayX Dashboard > My Account > Banking
# Required for API polling mode (replaces webhooks)
VYAPAAR_RAZORPAY_ACCOUNT_NUMBER=

# --- Google Safe Browsing v4 ---
# Get key: https://console.cloud.google.com/apis/credentials
# Enable: Safe Browsing API
VYAPAAR_GOOGLE_SAFE_BROWSING_KEY=AIzaSyXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX

# --- Redis ---
VYAPAAR_REDIS_URL=redis://localhost:6379/0

# --- PostgreSQL ---
VYAPAAR_POSTGRES_DSN=postgresql://vyapaar:securepass@localhost:5432/vyapaar_db

# --- Slack (Human-in-the-Loop, optional) ---
VYAPAAR_SLACK_BOT_TOKEN=xoxb-xxxxxxxxxxxx-xxxxxxxxxxxx
VYAPAAR_SLACK_CHANNEL_ID=CXXXXXXXXXX

# --- Server ---
VYAPAAR_HOST=0.0.0.0
VYAPAAR_PORT=8000
VYAPAAR_LOG_LEVEL=INFO

# --- Auto-Polling (optional) ---
# Enable background polling on server start (set to true for cron-style)
VYAPAAR_AUTO_POLL=false
# Polling interval in seconds (5-300)
VYAPAAR_POLL_INTERVAL=30

# Enable dev mode for testing (allows mock payouts)
VYAPAAR_DEV_MODE=false

# --- ngrok Tunnel (OPTIONAL — only if you prefer webhooks) ---
# Get your authtoken from: https://dashboard.ngrok.com/get-started/your-authtoken
# NGROK_AUTHTOKEN=your_ngrok_authtoken_here

# ============================================
# Microsoft Azure AI Foundry Configuration
# ============================================
# Azure AI Foundry is Microsoft's enterprise AI development platform.
# Archestra provides deterministic access policies as a proxy layer
# to protect against prompt injection attacks (lethal trifecta).
#
# Docs: https://learn.microsoft.com/en-us/azure/ai-foundry/

# --- Azure AI Foundry ---
# Your Azure OpenAI endpoint (e.g., https://<resource>.openai.azure.com/)
VYAPAAR_AZURE_OPENAI_ENDPOINT=https://<your-resource>.openai.azure.com/
# Azure OpenAI API key from Azure Portal > Keys and Endpoint
VYAPAAR_AZURE_OPENAI_API_KEY=<your-azure-openai-api-key>
# Deployment name of your model (e.g., gpt-4, gpt-4o)
VYAPAAR_AZURE_OPENAI_DEPLOYMENT=gpt-4o
# Azure AI Foundry Project ID (optional, for project-scoped resources)
VYAPAAR_AZURE_FOUNDRY_PROJECT_ID=
# API version (default: 2024-10-21)
VYAPAAR_AZURE_OPENAI_API_VERSION=2024-10-21

# --- Archestra Security Proxy (Deterministic Controls) ---
# Archestra sits as a proxy between your agent and MCP servers/LLM
# to enforce deterministic access policies instead of probabilistic guardrails.
# This protects against indirect prompt injection and sensitive data leakage.
# Docs: https://docs.archestra.ai
#
# For self-hosted Archestra, no external API key is needed.
# The proxy runs locally and enforces policies via its own gateway.
#
# Enable Archestra proxy layer (recommended for production)
VYAPAAR_ARCHESTRA_ENABLED=false
# Archestra URL for self-hosted instance (local proxy endpoint)
VYAPAAR_ARCHESTRA_URL=http://localhost:9000
# Archestra policy set ID to apply (defines allow/deny rules)
VYAPAAR_ARCHESTRA_POLICY_SET_ID=
# Archestra team token for gateway auth (self-hosted, generate locally)
# Generate with: archestra token generate --team <team-id>
# This is used by deploy/archestra.yaml, NOT a VYAPAAR_ prefixed var
ARCHESTRA_TEAM_TOKEN=

# --- AI Foundry Guardrails (Probabilistic - Use with caution) ---
# Azure's built-in guardrails are probabilistic and can be bypassed.
# We recommend using Archestra's deterministic controls instead.
# Enable Azure Foundry guardrails (jailbreak, indirect prompt injection detection)
VYAPAAR_AZURE_GUARDRAILS_ENABLED=false
# Moderation threshold: low (0), medium (1), high (2)
VYAPAAR_AZURE_GUARDRAILS_SEVERITY=1

# ============================================
# Dual LLM Quarantine Pattern (Security Layer)
# ============================================
# Reference: https://archestra.ai/docs/platform-dual-llm
#
# The Dual LLM pattern defends against the "lethal trifecta":
# - Indirect prompt injection via untrusted tool outputs
# - Sensitive data leakage through compromised context
# - Task drift caused by malicious instructions embedded in data
#
# How it works:
# 1. Primary LLM processes user request with full context (may be tainted)
# 2. When a tool call is made from TAINTED context, it's quarantined
# 3. Security LLM validates: tool name + params + GOVERNANCE POLICY only
# 4. Security LLM has NO access to tainted context (isolated)
# 5. Only proceeds if both LLMs agree OR security LLM approves

# --- Context Tainting (Auto-detected) ---
# Tools that mark context as untrusted when their output is used
# Comma-separated list of tool names
VYAPAAR_TAINT_SOURCES=handle_razorpay_webhook,poll_razorpay_payouts,check_vendor_reputation,verify_vendor_entity,score_transaction_risk

# --- Dual LLM Validation Tier ---
# Tools requiring security LLM validation when context is tainted
# Lower risk than "deny" tier, but still need isolation
VYAPAAR_DUAL_LLM_TOOLS=poll_razorpay_payouts,score_transaction_risk

# --- Security LLM Configuration ---
# Endpoint for the isolated security validation LLM
# This LLM has NO access to conversation context - only sees tool+params+policy
VYAPAAR_SECURITY_LLM_URL=http://localhost:9001/v1
# Security LLM API key (if required by local deployment)
VYAPAAR_SECURITY_LLM_KEY=
# Security LLM model name (e.g., gpt-4o-mini for cost-effective validation)
VYAPAAR_SECURITY_LLM_MODEL=gpt-4o-mini
# Max validation rounds before forcing deny (prevents loops)
VYAPAAR_DUAL_LLM_MAX_ROUNDS=5

# --- Quarantine Enforcement ---
# Strict mode: if security LLM fails/unavailable, DENY the tool call
VYAPAAR_QUARANTINE_STRICT=true
# Log all security LLM validation decisions for audit
VYAPAAR_QUARANTINE_AUDIT_LOG=true
